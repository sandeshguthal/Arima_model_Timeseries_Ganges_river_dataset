# -*- coding: utf-8 -*-
"""GroupAssignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dk9ReKGxRnZlpk8kDVByDO1L_bueK80Y
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
import warnings
import matplotlib.pylab as plt
# %matplotlib inline
from matplotlib.pylab import rcParams
from google.colab import files
import io
from statsmodels.tsa.arima_model import ARIMA

# Format data plots
rcParams['figure.figsize'] = 15, 6
rcParams['axes.titlesize'] = 'xx-large'
rcParams['axes.titleweight'] = 'bold'
rcParams["legend.loc"] = 'upper left'

# Import data set from Ganges_1996_2016  
dateparse = lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d')
#data = pd.read_csv(io.BytesIO(uploaded['Ganges_1996_2016.csv']), parse_dates=['Date'], index_col='Date',date_parser=dateparse)
data = pd.read_csv('http://kdl.cs.umb.edu/CS670/data/Ganges_1996_2016.csv', parse_dates=['Date'], index_col='Date',date_parser=dateparse)
# Check data has been properly parsed out
print(data.head())
print(data.iloc[-4:])
print(data.shape)

# Assign Data
qs = data['Q (m3/s)']
plt.title('TITTLLEEE')
plt.plot(qs)

# Split our data set
split_test = len(data) - 1827
ts, ts_test = qs[0:split_test], qs[split_test:]
print('Training %d, Test %d' % (len(ts), len(ts_test)))
print(ts)
print(ts_test)

# Checking for stationarity
from statsmodels.tsa.stattools import adfuller
def test_stationarity(ts):
  
    # Determing rolling statistics
    rawrolmean = ts.rolling(window=365, min_periods=310, center=False).mean()
    meanNoNuls = pd.notna(rawrolmean)
    rolmean = rawrolmean[meanNoNuls]
    rawrolstd = ts.rolling(window=365, min_periods=310, center=False).std()
    stdNoNuls = pd.notna(rawrolstd)
    rolstd = rawrolstd[stdNoNuls]
    
    # Plot rolling statistics:
    orig = plt.plot(ts, color='blue',label='Original')
    mean = plt.plot(rolmean, color='red', label='Rolling Mean')
    std = plt.plot(rolstd, color='black', label = 'Rolling Std')
    plt.legend(loc='best')
    plt.title('Rolling Mean & Standard Deviation')
    plt.show(block=False)
    
    # Perform Dickey-Fuller test:
    print ('Results of Dickey-Fuller Test:')
    dftest = adfuller(ts, autolag="AIC")
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])
    for key,value in dftest[4].items():
        dfoutput['Critical Value (%s)'%key] = value
    print (dfoutput)

ts.dropna(inplace=True)

test_stationarity(ts)

# Factoring out rolling average
rolmean = ts.rolling(window=365, center=False).mean()
ts_mean_dif = ts - rolmean
ts_mean_dif.dropna(inplace=True)

test_stationarity(ts_mean_dif)

#this is not used, just a test to see how stationary it makes the data

# Using Differencing
periods = 5
ts_dif = ts - ts.shift(periods=periods)
plt.plot(ts_dif)

ts_dif.dropna(inplace=True)

test_stationarity(ts_dif)

#ACF and PACF plots:
from statsmodels.tsa.stattools import acf, pacf

lag_acf = acf(ts_dif, nlags=20)
lag_pacf = pacf(ts_dif, nlags=20, method='ols')

#Plot ACF: 
plt.subplot(121) 
plt.plot(lag_acf)
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(ts_dif)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(ts_dif)),linestyle='--',color='gray')
plt.title('Autocorrelation Function')

#Plot PACF:
plt.subplot(122)
plt.plot(lag_pacf)
plt.axhline(y=0,linestyle='--',color='gray')
plt.axhline(y=-1.96/np.sqrt(len(ts_dif)),linestyle='--',color='gray')
plt.axhline(y=1.96/np.sqrt(len(ts_dif)),linestyle='--',color='gray')
plt.title('Partial Autocorrelation Function')
plt.tight_layout()

# invert differenced value
def inverse_difference(history, yhat, periods):
  logy = yhat + history[periods] 
  #print("history:"+str(history[-periods])+"pred:"+str(logy)) 
  return logy, logy

print (ts_test.shape)
print (ts_dif.shape)
model = ARIMA(ts_dif, order=(7, 1, 1))  
results_ARIMA = model.fit()
forecast = results_ARIMA.forecast(steps=1827)
print (forecast[0].shape)

"""Our best result for ARIMA predictions using the best values for p,d, and q."""

#start = pd.to_datetime('2011-01-01', format='%Y-%m-%d')
#end = pd.to_datetime('2012-12-31', format='%Y-%m-%d')

#start = '2011-01-01'
#end = '2012-12-31'


#forecast = results_ARIMA.predict(start=start,end=end)
forecast = results_ARIMA.forecast(steps=1827)[0]
print(forecast)
history = [x for x in ts.values]
history = history[-len(forecast):]
predictions = []
for i in range(len(forecast)):
  yhat = forecast[i]
#for yhat in forecast:
  logy, inverted = inverse_difference(history, yhat, i+periods)
  history.append(logy)
  predictions.append(inverted)
predictions_ARIMA = pd.DataFrame(predictions,index = ts_test.index)
print(predictions)
#predictions_ARIMA = pd.DataFrame(predictions)
plt.plot(qs)
plt.plot(predictions_ARIMA)
plt.title('RMSE: %.4f'% np.sqrt(sum((predictions-ts_test.values)**2)/len(ts_test)))

"""The above is our best solution for predicting the next five years all at once, using the ARIMA model.  Below, we have the "one step out of sample" solution, in which each day in the test set is only predicted the day before, taking into account the true values for all the days in the test set leading up to it, as is done in the "one step out of sample" portion of the lecture notes.  While this gives much more accurate predictions the predictions can only be made one day at a time versus years ahead."""

def makeInLoopOneDay(p, d, q, test_x):
  warnings.filterwarnings("ignore")
  periods=5
  predictions = []
  for i in range(split_test,len(qs)):
    #shows we are still running
    if(i%50 == 0):
      print('.')
    history = qs[0:i]
    ts_difference = history - history.shift(periods=periods)
    ts_difference.dropna(inplace=True)
    model = ARIMA(ts_difference, order=(p, d, q))
    results = model.fit()
    forecast = results.forecast(steps=1)[0]
    logy, inverted = inverse_diff(history, forecast[0], periods)
    predictions.append(inverted)
  predictions_ARIMA = pd.DataFrame(predictions,index = ts_test.index)
  plt.plot(qs)
  plt.plot(predictions_ARIMA)
  plt.title('RMSE: %.4f'% np.sqrt(sum((predictions-ts_test.values)**2)/len(ts_test)))

# invert differenced value
def inverse_diff(history, yhat, periods):
  logy = yhat + history[-periods] 
  return logy, logy

"""Note: below takes a few hours to run, do not re-run unless necessary"""

#Run this only if required for maximum accuracy, this takes upto a half a day to finish running
#makeInLoopOneDay(7, 1, 1, ts)

"""This method is obviously much more accurate in its predictions, but requires that we only predict one day into the future at a time.  Therefore it is more accurate but not necessarily as useful, as it only provides the prediction the day before."""